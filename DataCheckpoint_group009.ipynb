{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Andrew Hernandez\n",
    "- Austin Nguyen\n",
    "- Christian Kim\n",
    "- Kevin De Silva Jayasinghe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Does an increase in tweets with the hashtag description '#bitcoin' correlate with an increase in bitcoin price? What time frame relationship holds the strongest correlation?*\n",
    "- Does the number of tweets about bitcoin in one week correlate with the change in price of bitcoin the next week?\n",
    "- Is there a relationship between the number of tweets on a given day, and the change in price of bitcoin the day after?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your dataset information here*\n",
    "\n",
    "(Copy this information for each dataset)\n",
    "- Dataset Name: Bitcoin USD Price Data\n",
    "- Link to the dataset: https://www.marketwatch.com/investing/cryptocurrency/btcusd/download-data\n",
    "- Number of observations: 731\n",
    "\n",
    "This data set contains price history between 2019-2020 for Bitcoin on a daily basis showing open, high, low and close price. \n",
    "\n",
    "\n",
    "- Dataset Name: Bitcoin Tweets Historical chart\n",
    "- Link to the dataset: https://bitinfocharts.com/comparison/tweets-btc-ltc-eth.html#3y\n",
    "- Number of observations: 731\n",
    "\n",
    "This dataset is from a website that tracks the number of tweets with the hashtag phrase '#Bitcoin' per each day from 4-09-2014 to present day; however, we will only be using data from 01/01/2019 - 12/31/2020. We have made the decision to decrease our sample size and focus on a specific time period in order to examine this volatility and overall prices changes more closely on a per-week basis rather than examining years upon years of the dataset. By doing so, we will get a better idea whether a correlation between the increase in twitter tweets with the phrase #Bitcoin and an increase in Bitcoin price existed during this time frame.\n",
    "\n",
    "- Dataset Name: Twitter Monthly Active\n",
    "- Link to the dataset: https://www.businessofapps.com/data/twitter-statistics/\n",
    "- Number of observations: 8\n",
    "\n",
    "This Dataset was manually collected from the link above which illustrates the number of monthly active users broken down by quarter. We plan on using this dataset to normalize our tweet data because the number of monthly active users overtime affects the number of tweets containing #Bitcoin.\n",
    "\n",
    "We plan on combining these datasets by analyzing them statistically overtime and plotting the correlation between the normalized number of tweets (which we can get by using the Twitter Monthly Active and Bitcoin Tweets Historical chart datasets) containing #Bitcoin and the price of Bitcoin. Both datasets will have identical Date times for corresponding records (specific day and/or week timeframe) where we can then add a column for the number of tweets contianing #Bitcoin for that given Date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe your data cleaning steps here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    DateTimeGroup   Open  Close\n0      2019-01-01   3722   4040\n1      2019-01-08   4041   3693\n2      2019-01-15   3693   3537\n3      2019-01-22   3537   3442\n4      2019-01-29   3442   3445\n..            ...    ...    ...\n100    2020-12-01  19380  19087\n101    2020-12-08  19087  19201\n102    2020-12-15  19199  23146\n103    2020-12-22  23138  26634\n104    2020-12-29  26606  28966\n\n[105 rows x 3 columns]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           Date   Open   High    Low  Close  PriceChange   DateTime  \\\n",
       "0    12/31/2020  28898  29298  27989  28966           68 2020-12-31   \n",
       "1    12/30/2020  26870  28980  26870  28896         2026 2020-12-30   \n",
       "2    12/29/2020  26606  27164  25926  26870          264 2020-12-29   \n",
       "3    12/28/2020  26303  27404  26136  26634          331 2020-12-28   \n",
       "4    12/27/2020  26666  28326  25824  26303         -363 2020-12-27   \n",
       "..          ...    ...    ...    ...    ...          ...        ...   \n",
       "360  01/05/2019   3878   3912   3859   3880            2 2019-01-05   \n",
       "361  01/04/2019   3840   3895   3774   3878           38 2019-01-04   \n",
       "362  01/03/2019   3937   3964   3813   3841          -96 2019-01-03   \n",
       "363  01/02/2019   3767   3943   3757   3931          164 2019-01-02   \n",
       "364  01/01/2019   3722   3788   3697   3769           47 2019-01-01   \n",
       "\n",
       "    DateTimeGroup  \n",
       "0      2020-12-25  \n",
       "1      2020-12-24  \n",
       "2      2020-12-23  \n",
       "3      2020-12-22  \n",
       "4      2020-12-21  \n",
       "..            ...  \n",
       "360    2018-12-30  \n",
       "361    2018-12-29  \n",
       "362    2018-12-28  \n",
       "363    2018-12-27  \n",
       "364    2018-12-26  \n",
       "\n",
       "[731 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>PriceChange</th>\n      <th>DateTime</th>\n      <th>DateTimeGroup</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12/31/2020</td>\n      <td>28898</td>\n      <td>29298</td>\n      <td>27989</td>\n      <td>28966</td>\n      <td>68</td>\n      <td>2020-12-31</td>\n      <td>2020-12-25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12/30/2020</td>\n      <td>26870</td>\n      <td>28980</td>\n      <td>26870</td>\n      <td>28896</td>\n      <td>2026</td>\n      <td>2020-12-30</td>\n      <td>2020-12-24</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12/29/2020</td>\n      <td>26606</td>\n      <td>27164</td>\n      <td>25926</td>\n      <td>26870</td>\n      <td>264</td>\n      <td>2020-12-29</td>\n      <td>2020-12-23</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12/28/2020</td>\n      <td>26303</td>\n      <td>27404</td>\n      <td>26136</td>\n      <td>26634</td>\n      <td>331</td>\n      <td>2020-12-28</td>\n      <td>2020-12-22</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12/27/2020</td>\n      <td>26666</td>\n      <td>28326</td>\n      <td>25824</td>\n      <td>26303</td>\n      <td>-363</td>\n      <td>2020-12-27</td>\n      <td>2020-12-21</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>360</th>\n      <td>01/05/2019</td>\n      <td>3878</td>\n      <td>3912</td>\n      <td>3859</td>\n      <td>3880</td>\n      <td>2</td>\n      <td>2019-01-05</td>\n      <td>2018-12-30</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>01/04/2019</td>\n      <td>3840</td>\n      <td>3895</td>\n      <td>3774</td>\n      <td>3878</td>\n      <td>38</td>\n      <td>2019-01-04</td>\n      <td>2018-12-29</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>01/03/2019</td>\n      <td>3937</td>\n      <td>3964</td>\n      <td>3813</td>\n      <td>3841</td>\n      <td>-96</td>\n      <td>2019-01-03</td>\n      <td>2018-12-28</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>01/02/2019</td>\n      <td>3767</td>\n      <td>3943</td>\n      <td>3757</td>\n      <td>3931</td>\n      <td>164</td>\n      <td>2019-01-02</td>\n      <td>2018-12-27</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>01/01/2019</td>\n      <td>3722</td>\n      <td>3788</td>\n      <td>3697</td>\n      <td>3769</td>\n      <td>47</td>\n      <td>2019-01-01</td>\n      <td>2018-12-26</td>\n    </tr>\n  </tbody>\n</table>\n<p>731 rows Ã— 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Get daily bitcoin price from 01/01/2019 - 12/31/2019\n",
    "btc_2019 = pd.read_csv('btc_2019.csv')\n",
    "\n",
    "# Get daily bitcoin price from 01/01/2020 - 12/31/2020\n",
    "btc_2020 = pd.read_csv('btc_2020.csv')\n",
    "\n",
    "# Concatenate both years' data together into one dataframe\n",
    "btc_2019_2020 = pd.concat([btc_2020, btc_2019])\n",
    "\n",
    "# Remove commas of the open, high, low, and close to cast into int\n",
    "btc_2019_2020 = btc_2019_2020.replace(',', '', regex=True)\n",
    "\n",
    "# Cast the open, high, low, and close into ints so we can perform calculations on these values\n",
    "btc_2019_2020 = btc_2019_2020.astype({'Open': 'int32', 'High': 'int32', 'Low': 'int32', 'Close': 'int32'})\n",
    "\n",
    "# Create a new column called PriceChange which will be the difference between the close and open price.\n",
    "# We will use this to tell how much the price changed (will be used in measuring the correlation)\n",
    "btc_2019_2020 = btc_2019_2020.assign(PriceChange = (btc_2019_2020['Close'] - btc_2019_2020['Open']))\n",
    "\n",
    "# Create a new column which converts the Date into DateTime so it is easier to work with and graph\n",
    "btc_2019_2020['DateTime'] = pd.to_datetime(btc_2019_2020['Date'])\n",
    "\n",
    "# Create a new column which converts the Date into DateTime and subtract 6 days so we can group the daily prices into weekly prices\n",
    "# We will use this to group the data into weeks for the second part of the research question\n",
    "btc_2019_2020['DateTimeGroup'] = pd.to_datetime(btc_2019_2020['Date']) - pd.to_timedelta(6, unit='d')\n",
    "\n",
    "# Create two dataframes where the first gets the opening price of the week and the second gets the closing price of the week.\n",
    "# The keys will be the same so we can merge them to create a single table\n",
    "btc_2019_2020_weekly_open = btc_2019_2020.groupby(pd.Grouper(key='DateTimeGroup', freq='W-TUE'))[['Open']].first().reset_index().sort_values('DateTimeGroup')\n",
    "btc_2019_2020_weekly_close = btc_2019_2020.groupby(pd.Grouper(key='DateTimeGroup', freq='W-TUE'))[['Close']].last().reset_index().sort_values('DateTimeGroup')\n",
    "\n",
    "# Merge the two previous btc_2019_2020_weekly_open and btc_2019_2020_weekly_close tables.\n",
    "# This weekly form of the dataset has the key of the first day of the week (where we know the end date is the day before the next key)\n",
    "btc_2019_2020_weekly = pd.merge(btc_2019_2020_weekly_open, btc_2019_2020_weekly_close, on=['DateTimeGroup'])\n",
    "\n",
    "print(btc_2019_2020_weekly)\n",
    "btc_2019_2020\n",
    "# The datasets were split up by year so we had to concatenate\n",
    "# The data was already mostly clean so we only had to typecast the strings into integers and remove commas\n",
    "# We then added a column which contains PriceChange which is what we will use to determine\n",
    "# if the increase in tweets with the hashtag description '#bitcoin' correlates with an increase in bitcoin price\n",
    "# We also added a column for datetime to make it easy to work with and to create a dataframe where we group it by weekly prices\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            Date  BTC - Tweets\n",
       "0     2014/04/09          8193\n",
       "1     2014/04/10         15039\n",
       "2     2014/04/11         14907\n",
       "3     2014/04/12          7582\n",
       "4     2014/04/13         10674\n",
       "...          ...           ...\n",
       "2582  2021/05/04         87287\n",
       "2583  2021/05/05         93866\n",
       "2584  2021/05/06         84935\n",
       "2585  2021/05/07        103515\n",
       "2586  2021/05/08         21265\n",
       "\n",
       "[2531 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>BTC - Tweets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2014/04/09</td>\n      <td>8193</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2014/04/10</td>\n      <td>15039</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2014/04/11</td>\n      <td>14907</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2014/04/12</td>\n      <td>7582</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2014/04/13</td>\n      <td>10674</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2582</th>\n      <td>2021/05/04</td>\n      <td>87287</td>\n    </tr>\n    <tr>\n      <th>2583</th>\n      <td>2021/05/05</td>\n      <td>93866</td>\n    </tr>\n    <tr>\n      <th>2584</th>\n      <td>2021/05/06</td>\n      <td>84935</td>\n    </tr>\n    <tr>\n      <th>2585</th>\n      <td>2021/05/07</td>\n      <td>103515</td>\n    </tr>\n    <tr>\n      <th>2586</th>\n      <td>2021/05/08</td>\n      <td>21265</td>\n    </tr>\n  </tbody>\n</table>\n<p>2531 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# We found this web scraping script at https://stackoverflow.com/questions/47730259/installing-urllib-in-python3-6 \n",
    "# and made some minor modifications in order to fit to our needs in terms of retrieving the amount of tweets on a daily basis.\n",
    "# We have to further clean the data by extracting all days between 01/01/2019 - 12/31/2020 and then \n",
    "# grouping the data into a weekly format (sum amount of tweets for all days in a given week) \n",
    "# in order answer the second part of our question\n",
    "\n",
    "# Function to clean the string\n",
    "def parse_strlist(sl):\n",
    "    # Remove the uncessary commans and brackets\n",
    "    clean = re.sub(\"[\\[\\],\\s]\",\"\",sl)\n",
    "    # Split the remaining text by \" to a list where a date is followed by the number of tweets\n",
    "    splitted = re.split(\"[\\'\\\"]\",clean)\n",
    "    # Filter out empty segments of the array since the \" occurs at the beginning leading to an empty string in the list\n",
    "    values_only = [s for s in splitted if s != '']\n",
    "    return values_only\n",
    "\n",
    "# Make a request to the website with the dataset and parse its html\n",
    "url = 'https://bitinfocharts.com/comparison/tweets-btc.html#3y'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Since the data is stored in the script tags we will search in there\n",
    "scripts = soup.find_all('script', text=True)\n",
    "for script in scripts:\n",
    "    # The script tag we are looking for contains this content inside so we will parse it if we find this string inside\n",
    "    if 'd = new Dygraph(document.getElementById(\"container\")' in str(script):\n",
    "        # Since there are various things inside the script tag, we will search for the array holding the date specifically\n",
    "        StrList = str(script)\n",
    "        StrList = '[[' + StrList.split('[[')[-1]\n",
    "        StrList = StrList.split(']]')[0] +']]'\n",
    "        # We will replace the js date parser surrounding the date we want\n",
    "        StrList = StrList.replace(\"new Date(\", '').replace(')','')\n",
    "        # Parse the string into an list so we can create the dataframe\n",
    "        dataList = parse_strlist(StrList)\n",
    "\n",
    "        # Make a dataframe from the parsed data\n",
    "        date = []\n",
    "        tweet = []\n",
    "        for each in dataList:\n",
    "            if (dataList.index(each) % 2) == 0:\n",
    "                date.append(each)\n",
    "            else:\n",
    "                tweet.append(each)\n",
    "        tweet_df = pd.DataFrame(list(zip(date, tweet)), columns=[\"Date\",\"BTC - Tweets\"])\n",
    "\n",
    "# This dataframe has one null value so we will need to remove it\n",
    "tweet_df = tweet_df[tweet_df[\"BTC - Tweets\"] != \"null\"]\n",
    "\n",
    "# Cast the tweet count into ints so we can perform calculations on these values\n",
    "tweet_df = tweet_df.astype({'BTC - Tweets': 'int64'})\n",
    "\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            Date  BTC - Tweets   DateTime DateTimeGroup\n",
      "1728  2019/01/01         17069 2019-01-01    2018-12-26\n",
      "1729  2019/01/02         18830 2019-01-02    2018-12-27\n",
      "1730  2019/01/03         26754 2019-01-03    2018-12-28\n",
      "1731  2019/01/04         21139 2019-01-04    2018-12-29\n",
      "1732  2019/01/05         20096 2019-01-05    2018-12-30\n",
      "...          ...           ...        ...           ...\n",
      "2454  2020/12/27         88788 2020-12-27    2020-12-21\n",
      "2455  2020/12/28         59779 2020-12-28    2020-12-22\n",
      "2456  2020/12/29         56236 2020-12-29    2020-12-23\n",
      "2457  2020/12/30         80886 2020-12-30    2020-12-24\n",
      "2458  2020/12/31         68822 2020-12-31    2020-12-25\n",
      "\n",
      "[730 rows x 4 columns]\n",
      "<ipython-input-5-f0bbf4b1f75f>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_2019_2020['DateTime'] = pd.to_datetime(tweets_2019_2020['Date'])\n",
      "<ipython-input-5-f0bbf4b1f75f>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_2019_2020['DateTimeGroup'] = pd.to_datetime(tweets_2019_2020['Date']) - pd.to_timedelta(6, unit='d')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    DateTimeGroup  BTC - Tweets\n",
       "0      2019-01-01        143247\n",
       "1      2019-01-08        132086\n",
       "2      2019-01-15        130601\n",
       "3      2019-01-22        125986\n",
       "4      2019-01-29        123895\n",
       "..            ...           ...\n",
       "100    2020-12-01        323904\n",
       "101    2020-12-08        278768\n",
       "102    2020-12-15        539526\n",
       "103    2020-12-22        402965\n",
       "104    2020-12-29        205944\n",
       "\n",
       "[105 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DateTimeGroup</th>\n      <th>BTC - Tweets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-01-01</td>\n      <td>143247</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-01-08</td>\n      <td>132086</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-01-15</td>\n      <td>130601</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-01-22</td>\n      <td>125986</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-01-29</td>\n      <td>123895</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>2020-12-01</td>\n      <td>323904</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>2020-12-08</td>\n      <td>278768</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>2020-12-15</td>\n      <td>539526</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>2020-12-22</td>\n      <td>402965</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>2020-12-29</td>\n      <td>205944</td>\n    </tr>\n  </tbody>\n</table>\n<p>105 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Filter our tweet dataframe so that we only include the tweet counts from the years 2019 and 2020\n",
    "tweets_2019_2020 = tweet_df[(tweet_df.Date.str.contains(\"2019\", na=False)) | (tweet_df.Date.str.contains(\"2020\", na=False))]\n",
    "\n",
    "# Create a new column which converts the Date into DateTime so it is easier to work with and graph\n",
    "tweets_2019_2020['DateTime'] = pd.to_datetime(tweets_2019_2020['Date'])\n",
    "\n",
    "# Create a new column which converts the Date into DateTime and subtract 6 days so we can group the daily tweet count into tweet count prices\n",
    "# We will use this to group the data into weeks for the second part of the research question\n",
    "tweets_2019_2020['DateTimeGroup'] = pd.to_datetime(tweets_2019_2020['Date']) - pd.to_timedelta(6, unit='d')\n",
    "\n",
    "# Group the number of tweets by week\n",
    "tweets_2019_2020_weekly = tweets_2019_2020.groupby(pd.Grouper(key='DateTimeGroup', freq='W-TUE'))[['BTC - Tweets']].sum().reset_index().sort_values('DateTimeGroup')\n",
    "\n",
    "print(tweets_2019_2020)\n",
    "tweets_2019_2020_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Quarter  Year          MUA\n",
       "0      Q1  2019  330000000.0\n",
       "1      Q2  2019  330000000.0\n",
       "2      Q3  2019  330000000.0\n",
       "3      Q4  2019  340000000.0\n",
       "4      Q1  2020  326000000.0\n",
       "5      Q2  2020  326000000.0\n",
       "6      Q3  2020  353000000.0\n",
       "7      Q4  2020          NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Quarter</th>\n      <th>Year</th>\n      <th>MUA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q1</td>\n      <td>2019</td>\n      <td>330000000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q2</td>\n      <td>2019</td>\n      <td>330000000.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q3</td>\n      <td>2019</td>\n      <td>330000000.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Q4</td>\n      <td>2019</td>\n      <td>340000000.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Q1</td>\n      <td>2020</td>\n      <td>326000000.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Q2</td>\n      <td>2020</td>\n      <td>326000000.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Q3</td>\n      <td>2020</td>\n      <td>353000000.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Q4</td>\n      <td>2020</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "twitter_monthly_users_data = { 'Quarter': ['Q1', 'Q2', 'Q3', 'Q4', 'Q1', 'Q2', 'Q3', 'Q4'],\n",
    "         'Year': [2019,2019,2019,2019,2020,2020,2020,2020],\n",
    "         'MUA':  [330000000,330000000,330000000,340000000,326000000,326000000,353000000,np.nan]}\n",
    "\n",
    "twitter_monthly_users = pd.DataFrame(twitter_monthly_users_data)\n",
    "twitter_monthly_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python395jvsc74a57bd03a9edbe0614845e4741d6ef5998e440eef8a13a2553455bf6fe17e1a001dd031",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "3a9edbe0614845e4741d6ef5998e440eef8a13a2553455bf6fe17e1a001dd031"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}